{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This exercise will require you to pull some data from https://data.nasdaq.com/ (formerly Quandl API)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a first step, you will need to register a free account on the https://data.nasdaq.com/ website."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you register, you will be provided with a unique API key, that you should store:\n",
    "\n",
    "*Note*: Use a `.env` file and put your key in there and `python-dotenv` to access it in this notebook. \n",
    "\n",
    "The code below uses a key that was used when generating this project but has since been deleted. Never submit your keys to source control. There is a `.env-example` file in this repository to illusrtate what you need. Copy that to a file called `.env` and use your own api key in that `.env` file. Make sure you also have a `.gitignore` file with a line for `.env` added to it. \n",
    "\n",
    "The standard Python gitignore is [here](https://github.com/github/gitignore/blob/master/Python.gitignore) you can just copy that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get api key from your .env file\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv('NASDAQ_API_KEY')\n",
    "\n",
    "# print(API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nasdaq Data has a large number of data sources, but, unfortunately, most of them require a Premium subscription. Still, there are also a good number of free datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this mini project, we will focus on equities data from the Frankfurt Stock Exhange (FSE), which is available for free. We'll try and analyze the stock prices of a company called Carl Zeiss Meditec, which manufactures tools for eye examinations, as well as medical lasers for laser eye surgery: https://www.zeiss.com/meditec/int/home.html. The company is listed under the stock ticker AFX_X."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find the detailed Nasdaq Data API instructions here: https://docs.data.nasdaq.com/docs/in-depth-usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While there is a dedicated Python package for connecting to the Nasdaq API, we would prefer that you use the *requests* package, which can be easily downloaded using *pip* or *conda*. You can find the documentation for the package here: http://docs.python-requests.org/en/master/ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, apart from the *requests* package, you are encouraged to not use any third party Python packages, such as *pandas*, and instead focus on what's available in the Python Standard Library (the *collections* module might come in handy: https://pymotw.com/3/collections/).\n",
    "Also, since you won't have access to DataFrames, you are encouraged to us Python's native data structures - preferably dictionaries, though some questions can also be answered using lists.\n",
    "You can read more on these data structures here: https://docs.python.org/3/tutorial/datastructures.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep in mind that the JSON responses you will be getting from the API map almost one-to-one to Python's dictionaries. Unfortunately, they can be very nested, so make sure you read up on indexing dictionaries in the documentation provided above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, import the relevant modules\n",
    "import requests\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: API's can change a bit with each version, for this exercise it is reccomended to use the nasdaq api at `https://data.nasdaq.com/api/v3/`. This is the same api as what used to be quandl so `https://www.quandl.com/api/v3/` should work too.\n",
    "\n",
    "Hint: We are looking for the `AFX_X` data on the `datasets/FSE/` dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Collect data from the Franfurt Stock Exchange, for the ticker AFX_X, for the whole year 2017 (keep in mind that the date format is YYYY-MM-DD).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the url using variables \n",
    "\n",
    "database = 'FSE'\n",
    "dataset = 'AFX_X'\n",
    "start_date = '2017-01-01'\n",
    "end_date = '2017-12-31'\n",
    "\n",
    "#in the previews submit, accidently set the year for start_date and end_date to 2007, instead o\n",
    "\n",
    "url = \"https://data.nasdaq.com/api/v3/datasets\" + \"/\"+database+'/'+dataset+'/data.json?start_date='+start_date+'&end_date='+end_date+'&api_key='+API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Convert the returned JSON object into a Python dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# get the data object and store to variable 'afx'\n",
    "\n",
    "r = requests.get(url)\n",
    "afx = json.loads(r.text)\n",
    "# afx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The extracted JSON data is structured as a  **multidimensional** dictionary. The relevant information we are interested in is nested inside the main dictionary ('afx') under the key \"dataset_data\". Within this nested dictionary, we need to extract the values associated with the keys **'column_names'** and **'data'**. \n",
    "<br/>Let's further explore and retrieve these values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((255, 11), (11,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(afx['dataset_data']['data']), np.shape(afx['dataset_data']['column_names'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'data' is represented as a 2D list with 255 sublists, each containing 11 elements, which matches the shape of the 'column_names' list. We will proceed by creating a new Python dictionary called **'afx_data'** using the column names as keys and assigning the 'data' records as their corresponding values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an empty dictionary\n",
    "afx_data = {}\n",
    "\n",
    "# Itinerate through column names\n",
    "for col in range(0,11):\n",
    "    # Get the column name\n",
    "    col_name = afx['dataset_data']['column_names'][col]\n",
    "    # Create an empty list to store column values\n",
    "    afx_data[col_name] = []\n",
    "    \n",
    "    # itinerate through values\n",
    "    for val in range(0,255):\n",
    "        # append the column values to he corresponding list\n",
    "        afx_data[col_name].append(afx['dataset_data']['data'][val][col]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Date', 'Open', 'High', 'Low', 'Close', 'Change', 'Traded Volume', 'Turnover', 'Last Price of the Day', 'Daily Traded Units', 'Daily Turnover'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "afx_data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Calculate what the highest and lowest opening prices were for the stock in this period.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's check if the column 'Open' has the correct datatype:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert it to a np array and check the datatypes:\n",
    "open_array = np.array(afx_data['Open'])\n",
    "open_array.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are different data types in the list / array. \n",
    "<br>We'll create a function called `get_dtype_counts()` that takes a list as input and returns a dictionary with all the data types present in the list along with their counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dtype_counts(li):\n",
    "    dt_types = {}\n",
    "    for value in li:\n",
    "        if type(value) not in dt_types:\n",
    "            dt_types[type(value)] = 1\n",
    "        else:\n",
    "            dt_types[type(value)] += 1\n",
    "        \n",
    "    return(dt_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{float: 252, NoneType: 3}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_dtype_counts(afx_data['Open'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'Open' column has the correct datatype, but has ***3 missing values***\n",
    "<p>\n",
    "Now we find the min and max values in the list and their indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Value: 53.11\n",
      "Max Index: 9\n",
      "Min Value: 34.0\n",
      "Min Index: 238\n"
     ]
    }
   ],
   "source": [
    "max_value = None\n",
    "max_index = None\n",
    "min_value = None\n",
    "min_index = None\n",
    "\n",
    "for index, value in enumerate(afx_data['Open']):\n",
    "    if value is not None:\n",
    "        if max_value is None or value > max_value:\n",
    "            max_value = value\n",
    "            max_index = index\n",
    "        if min_value is None or value < min_value:\n",
    "            min_value = value\n",
    "            min_index = index\n",
    "\n",
    "print(\"Max Value:\", max_value)\n",
    "print(\"Max Index:\", max_index)\n",
    "print(\"Min Value:\", min_value)\n",
    "print(\"Min Index:\", min_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The highest opening price ocurred on 2017-12-14 and has the value 53.11\n",
      "The Lowest opening price ocurred on 2017-01-24 and has the value 34.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"The highest opening price ocurred on {afx_data['Date'][max_index]} and has the value {max_value}\")\n",
    "print(f\"The Lowest opening price ocurred on {afx_data['Date'][min_index]} and has the value {min_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. What was the largest change in any one day (based on High and Low price)?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({float: 255}, {float: 255})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the `get_dtype_counts()` to check the datatypes:\n",
    "get_dtype_counts(afx_data['High']), get_dtype_counts(afx_data['Low']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both columns have the data stored correctly, datatype is float without any missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The largest change occured on 2017-05-11 where the Highest value hit 46.06 and the Lowest 43.25.\n",
      "The difference was 2.8100000000000023\n"
     ]
    }
   ],
   "source": [
    "max_change = 0\n",
    "for i in range(0,len(afx_data['High'])):\n",
    "    if afx_data['High'][i] !=None and afx_data['Low'][i] !=None :\n",
    "        delta = abs(afx_data['High'][i] - afx_data['Low'][i])\n",
    "        if max_change < delta:\n",
    "            max_change = delta\n",
    "            index = i\n",
    "            \n",
    "print(f\"The largest change occured on {afx_data['Date'][index]} where the Highest value hit {afx_data['High'][index]} and the Lowest {afx_data['Low'][index]}.\\nThe difference was {max_change}\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. What was the largest change between any two days (based on Closing Price)?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{float: 255}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for datatypes and missing values\n",
    "\n",
    "get_dtype_counts(afx_data['Close'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the data types are float, there are no missing values in the column 'Close'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The largest change between any two days, based on the Closing Price, occured when the price \n",
      "changed from $41.81 on 2017-08-09 to $44.37 on 2017-08-08 \n",
      "with an absolute difference of $2.559999999999995\n"
     ]
    }
   ],
   "source": [
    "closing_prices = afx_data['Close']\n",
    "\n",
    "# using np.diff() to get the list of the differences, and np.abs() to get the absolute values\n",
    "diffs = np.abs(np.diff(closing_prices))\n",
    "\n",
    "# np.argmax() will give the index of the largest change\n",
    "max_change_index = np.argmax(diffs)\n",
    "max_change = diffs[max_change_index]\n",
    "\n",
    "print(f\"The largest change between any two days, based on the Closing Price, occured when the price \\nchanged from ${afx_data['Close'][max_change_index]} on {afx_data['Date'][max_change_index]} to ${afx_data['Close'][max_change_index+1]} on {afx_data['Date'][max_change_index+1]} \\nwith an absolute difference of ${max_change}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. What was the average daily trading volume during this year?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{float: 255}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_dtype_counts(afx_data['Traded Volume'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Traded Volume` column has a **float** data type and ***no missing values***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The calculated average daily trading volume for AFX_X in the year 2017 is approximately 89124.33725490196\n"
     ]
    }
   ],
   "source": [
    "# store the trading volume column into a list using list comprehension to remove None values\n",
    "trading_volume = [x for x in afx_data['Traded Volume'] if x != None]\n",
    "\n",
    "# calculate the mean\n",
    "avg_daily_vol = sum(trading_volume)/len(trading_volume)\n",
    "\n",
    "print(f\"The calculated average daily trading volume for AFX_X in the year 2017 is approximately {avg_daily_vol}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. (Optional) What was the median trading volume during this year. (Note: you may need to implement your own function for calculating the median.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to find the median\n",
    "def median(li):\n",
    "    #sort the list\n",
    "    li =sorted(li)\n",
    "    \n",
    "    #if the list length is odd, the element in the middle is the median\n",
    "    if len(li) %2 == 1:\n",
    "        median_index = int((len(li)+1) / 2)-1\n",
    "        \n",
    "        return (li[median_index])\n",
    "    \n",
    "    # the length is even, the average of the two elements in center is the median\n",
    "    else:\n",
    "        median_index =int(len(li) / 2)\n",
    "        return (li[median_index-1] + li[median_index]) / 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The median trading volume during 2017 was 76286.0\n"
     ]
    }
   ],
   "source": [
    "print(f\" The median trading volume during 2017 was {median(trading_volume)}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7635eb1b9d0fe97add78a7368b6b431c09bb8ad5c42e437d64abdd99821c31ae"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
